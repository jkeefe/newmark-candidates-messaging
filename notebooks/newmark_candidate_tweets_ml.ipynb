{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2FtGCN6bVsg"
   },
   "source": [
    "# Finding Fear-mongering Tweets with Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fveMUfklKAt8"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Our challenge is to find tweets by US congressional candidates that are **examples of fear-mongering**.\n",
    "\n",
    "Recognizing fear mongering seems like it might be a uniquely human skill. But we can make a machine-learning mmodel that does it pretty well.\n",
    "\n",
    "### First, the language model\n",
    "\n",
    "We'll get into the details below, but here's our two-step process for this project:\n",
    "\n",
    "First, we need a model trained to recognize the patterns of English. For that, we'd need some huge dataset of English-language text. Fortunately, someone has already done that for us! We'll be using a model trained on thousands of long Wikipedia articles. It's called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset).\n",
    "\n",
    "We'll then use _transfer learning_ (like we did in for the helicopter maps) to further train wikitext-103 on our particular corpus: a few thousand candidate tweets. So we benefit from it's training on both English-language articles _and_ the tweets.\n",
    "\n",
    "That will give us a **language model** that's good at detecting patterns in candidate tweets.\n",
    "\n",
    "\n",
    "### Second, the classification model\n",
    "\n",
    "Next we need a model that will sort -- aka _classify_ -- tweets into fear-mongering and not. This will combine the patern-recognition embedded in the language model and examples of both kinds of tweets to make a predition on which class _new_ tweets belong to. This is our **classification model**.\n",
    "\n",
    "\n",
    "## The Plan\n",
    "\n",
    "Here's what we're going to do:\n",
    "\n",
    "- Grab files with a bunch of tweets\n",
    "- Make a **language model** from a model pretrained on Wikipedia _plus_ all the tweets as we have\n",
    "- Make a **classification model** to predict whether a given tweet is checkable or not, using tweets that were hand-labeled by students in the Newmark J-School's online investigations class.\n",
    "- Use that classification model to predict the fear-mongering status of unseen tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7K01TybPKAt9"
   },
   "source": [
    "## Credits\n",
    "\n",
    "This notebook was based on one originally created by Jeremy Howard and the other folks at [fast.ai](https://fast.ai) as part of [this fantastic class](https://course.fast.ai/). Specifically, it comes from Lesson 4. You can [see the lession video](https://course.fast.ai/videos/?lesson=4) and [the original class notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb). \n",
    "\n",
    "The idea for the project came from students in the Newmark J-School's online investigations class. Tweets were coded by Ben Abrams, Holly Deaton, Christine Derosa, Amanda Glodowski, Elias Guerra, May Olvera, Luca Powell, Sam Sharpe, and Jacob Wasserman.\n",
    "\n",
    "-- John Keefe, [Quartz](https://qz.com), May 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-43jn3dcKAt9"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHuCQQgwKAt-"
   },
   "source": [
    "### For those using Google Colaboratory ...\n",
    "\n",
    "Be aware that Google Colab instances are ephemeral -- they vanish *Poof* when you close them, or after a period of sitting idle (currently 90 minutes), or if you use one for more than 12 hours.\n",
    "\n",
    "If you're using Google Colaboratory, be sure to set your runtime to \"GPU\" which speeds up your notebook for machine learning:\n",
    "\n",
    "![change runtime](https://qz-aistudio-public.s3.amazonaws.com/workshops/notebook_images/change_runtime_2.jpg)\n",
    "![pick gpu](https://qz-aistudio-public.s3.amazonaws.com/workshops/notebook_images/pick_gpu_2.jpg)\n",
    "\n",
    "Then run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "27X2fIFLKAt_",
    "outputId": "84b82995-65b9-4d24-ccf3-d3424e3b1d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fastai...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "## ALL GOOGLE COLAB USERS RUN THIS CELL\n",
    "\n",
    "## This runs a script that installs fast.ai\n",
    "!curl -s https://course.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rb5MHkaGKAuE"
   },
   "source": [
    "### For those _not_ using Google Colaboratory ...\n",
    "\n",
    "This section is just for people who decide to use one of the notebooks on a system other than Google Colaboartory. \n",
    "\n",
    "Those people should run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEaveBpwKAuF"
   },
   "outputs": [],
   "source": [
    "## NON-COLABORATORY USERS SHOULD RUN THIS CELL\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8pBM_VSKAuO"
   },
   "source": [
    "### Everybody do this ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-66OxTIKAuO"
   },
   "source": [
    "Everyone needs to run the next cell, which initializes the Python libraries we'll use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "aOKL5JRIKAuP",
    "outputId": "f8ebdb90-34b7-4d2b-b600-8cf99d6f717d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai: 1.0.61\n",
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "## AND *EVERYBODY* SHOULD RUN THIS CELL\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from fastai.text import *\n",
    "import fastai\n",
    "print(f'fastai: {fastai.__version__}')\n",
    "print(f'cuda: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icx8GPCwKAuV"
   },
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpGD29R1KAuW"
   },
   "source": [
    "We're going to be using two sets of tweets for this project:\n",
    "\n",
    "- A CSV (comma-separated values file) containing a corpus of tweets\n",
    "- A CSV of tweets that have been hand-coded as \"fear-mongering\" (true or false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "u-geWZpnKAuW",
    "outputId": "59254740-54e4-4f66-fadb-d316f6f60450",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to download the data we'll use for this exercise\n",
    "!wget -N https://s3.amazonaws.com/media.johnkeefe.net/newmark-investigations/corpus.csv --quiet\n",
    "!wget -N https://s3.amazonaws.com/media.johnkeefe.net/newmark-investigations/scored.csv --quiet\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J00lMZjlKAuZ"
   },
   "source": [
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CV0uM9iNKAua",
    "outputId": "232abed8-4937-4650-a474-e865a40a1443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus.csv  \u001b[0m\u001b[01;36mdata\u001b[0m@  \u001b[01;36mmodels\u001b[0m@  scored.csv\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TPvnzypbVsq"
   },
   "source": [
    "### Take a peek at the tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I21aOI9xbVsr"
   },
   "source": [
    "The Newmark J-School students coded the tweets as \"fear-mongering\" specifically about the Covid-19 pandemic, and about other topics. We then created an \"either\" column for fear mongering of either type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "kWwuVUg9QHo8",
    "outputId": "f33d8f97-0e93-4159-fc2f-15d2fcf919a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>covid_final</th>\n",
       "      <th>other_final</th>\n",
       "      <th>covid</th>\n",
       "      <th>other</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you to all those fighting COVID-19 on th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Arizona Department of Health Services has ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Arizona Department of Health Services has ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @animalag: FFA and 4-H members are lending ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As of today, I am officially on the ballot for...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  ...  either\n",
       "0  Thank you to all those fighting COVID-19 on th...  ...   False\n",
       "1  The Arizona Department of Health Services has ...  ...   False\n",
       "2  The Arizona Department of Health Services has ...  ...   False\n",
       "3  RT @animalag: FFA and 4-H members are lending ...  ...   False\n",
       "4  As of today, I am officially on the ballot for...  ...   False\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I read the csv into a data frame I called `austin_tweets`\n",
    "# and take a look at the first few rows\n",
    "data_path = './'\n",
    "hand_coded_tweets = pd.read_csv(data_path + 'scored.csv')\n",
    "hand_coded_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULW4TiDjKAul"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "18kBCGjhbVvQ",
    "outputId": "f8e69a84-1967-4fae-f17d-79da6e339648"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you to all those fighting COVID-19 on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Arizona Department of Health Services has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Arizona Department of Health Services has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @animalag: FFA and 4-H members are lending ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As of today, I am officially on the ballot for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  Thank you to all those fighting COVID-19 on th...\n",
       "1  The Arizona Department of Health Services has ...\n",
       "2  The Arizona Department of Health Services has ...\n",
       "3  RT @animalag: FFA and 4-H members are lending ...\n",
       "4  As of today, I am officially on the ballot for..."
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the corpus, which has one tweet per row,\n",
    "# and take a look at the first frew rows\n",
    "corpus_tweets = pd.read_csv(data_path + 'corpus.csv')\n",
    "corpus_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eym6ulq0bVuz"
   },
   "source": [
    "## Building the language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62pxEwWPbVvI"
   },
   "source": [
    "First we need a model that 'understands' the rules of English, and ideally also recognizes patterns in our particular corpus. This is the language model. \n",
    "\n",
    "We'll start with a language model pretrained on a thousands of Wikipedia articles called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset). That language model has been trained to guess the next word in a sentence based on all the previous words. It has a recurrent structure with a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
    "\n",
    "For our project, we want to infuse the Wikitext model with our particular dataset – the #txlege tweets. Because the English of candidate tweets isn't the same as the English of Wikipedia, we'll adjust the internal parameters of the model by a little bit. That includes adding words that might be extremely common in the tweets but would be barely present in wikipedia–and therefore might not be part of the vocabulary the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FT0C6-vpbVvK"
   },
   "source": [
    "### Using all of our tweets for the language model\n",
    "\n",
    "We want as many tweets for the language model as possible to learn the patterns of candidate tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "aQyQIh_vNhrH",
    "outputId": "76bb719a-89f8-4efd-e112-160199f6ec99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand coded tweets: 3215\n",
      "corpus of tweets: 4002\n",
      "total tweets: 4002\n"
     ]
    }
   ],
   "source": [
    "# here I concatenate the two tweet sets into one big set\n",
    "lm_tweets = corpus_tweets\n",
    "\n",
    "# as a sanity check, let's look at the size of each set, \n",
    "# and then the ontatenated set\n",
    "print('hand coded tweets:', len(hand_coded_tweets) )\n",
    "print('corpus of tweets:', len(corpus_tweets) )\n",
    "print('total tweets:', len(lm_tweets) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure there's an entry on every row of the language model tweets, so we check to see if there are any \"null\" values using this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4TQXVe4PLUeX",
    "outputId": "627c3b24-4b51-415c-f783-9f0b77e3ead4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_tweets.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, yes, there are a few. That will trip up the model. So let's zap 'em."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSeubZIqLrPo"
   },
   "outputs": [],
   "source": [
    "lm_tweets.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aAIgU3nSL2aj",
    "outputId": "0e62d3ac-2941-4680-d734-3a0fb0b69830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_tweets.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFp92p9NbVvs"
   },
   "outputs": [],
   "source": [
    "# Saving as csv for easier reading in a moment\n",
    "lm_tweets.to_csv(data_path + 'lm_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fU_R9lxbVv7"
   },
   "source": [
    "Fast.ai uses a concept called a \"[data bunch](https://docs.fast.ai/basic_data.html)\" to handle machine-learning data, which takes care of a lot of the more fickle machine-learning data preparation.\n",
    "\n",
    "We have to use a special kind of data bunch for the language model, one that ignores the labels, and will shuffle the texts at each epoch before concatenating them all together (only the training set gets shuffled; we don't shuffle for the validation set). It will also create batches that read the text in order with targets (aka the best guesses) that are the next word in the sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "C2rJuWVCbVv5",
    "outputId": "78e0686e-3777-440c-9078-7e6e648b1275"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading in data with the TextLMDataBunch factory class, using all the defaults\n",
    "data_lm = TextLMDataBunch.from_csv(data_path, 'lm_tweets.csv', text_cols='content', label_cols='either')\n",
    "data_lm.save('data_lm_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rY0LkJCQbVwF"
   },
   "source": [
    "We can then put all of our tweets (now stored in `data_lm`) into a learner object along with the pretrained Wikitext model -- here called `AWD_LTSM`, which is downloaded the first time you'll execute the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EiiXrA6zbVwH",
    "outputId": "1c778e85-f921-4772-9257-a0eca46d1377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfAXUyLnOB_J"
   },
   "source": [
    "One of the most important settings when we actually _train_ our model is the **learning rate**. I'm not going to dive into it here (though I encourage you to explore it), but will use a fast.ai tool to find the best learning rate to start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "W7b-Z94dbVwL",
    "outputId": "9042bfb1-cd33-4c21-d923-435b54096abc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      66.67% [2/3 00:10<00:05]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.552738</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.134435</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='27' class='' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      75.00% [27/36 00:03<00:01 9.5131]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "my_model.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "Un204GpfbVwO",
    "outputId": "15410852-79b7-4645-f4ee-f6bc09a089c9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "td3D3mK8TtHa"
   },
   "source": [
    "This gives us a graph of the optimal learning rate ... which is the point where the graph really dives downward (`1e-02`). Again, there's much more on picking and learning rates in the fast.ai course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQA3dZWPachE"
   },
   "source": [
    "Now we can train the Language Model. (Essentailly, we're training it to be good at guessing the *next word* in a sentence, given all of the previous words.)\n",
    "\n",
    "The variabales we're passing are `1` to just do one cycle of learning, the learning rate of `1e-2`, and some momentum settings we won't get into here -- but these are pretty safe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "pveLnA6kbVwQ",
    "outputId": "4c6c5d33-e1bc-49a4-d45b-f76a0878791c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.305858</td>\n",
       "      <td>3.604853</td>\n",
       "      <td>0.362029</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "o-dYIVFcbVwS",
    "outputId": "8e7629a5-7b4c-4b8b-d717-3d6cb48da257"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.661641</td>\n",
       "      <td>3.383069</td>\n",
       "      <td>0.377530</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model.fit_one_cycle(1, 1e-1, moms=(0.8,0.7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8kZOKSybVwX"
   },
   "source": [
    "To complete the fine-tuning, we \"unfreeze\" the original wikitext-103 language model and let our new training efforts work their way into the original neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "kTfuNCuhbVwX",
    "outputId": "91ac1e33-b952-4558-9536-0305f0d6b4a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.881653</td>\n",
       "      <td>3.223611</td>\n",
       "      <td>0.397520</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.654814</td>\n",
       "      <td>3.216478</td>\n",
       "      <td>0.401563</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This takes a couple of minutes!\n",
    "my_model.unfreeze()\n",
    "my_model.fit_one_cycle(2, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fv0mZuVhbVwd"
   },
   "source": [
    "While our accuracy may _seem_ low ... in this case it means the language model correctly guessed the next word in a sentence more than 1/3 of the time. That's pretty good! And we can see that even when it's wrong, it makes some pretty \"logical\" guesses. \n",
    "\n",
    "Let's give it a starting phrase and see how it does:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "_Wws03kmbVwd",
    "outputId": "5a7cc859-733e-43d9-e0a3-2267a9797e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to thank everyone who attended our Facebook live town hall ! https : / / t.co / ol5bezhln3 xxbos Today 's Endorser of the Day is Tom Lloyd ! \n",
      " \n",
      "  We are proud of\n",
      "\n",
      "I want to thank the President for working hard to flatten the curve in # MN01 . We continue to make sure we all have this # COVID19 crisis we can not allow . We should be grateful .\n",
      "\n",
      "I want to thank everyone who came out to speak about the issues in the district and to answer a answer on # coronavirus . We need to answer a question and answer a solution . Learn more . My questions\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"I want to thank\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 3\n",
    "\n",
    "print(\"\\n\\n\".join(my_model.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hj3aD0UebVwr"
   },
   "source": [
    "Remember, these are not real ... they were _generated_ by the model when it tried to guess each of the next words in the sentence! Generating text like this is not why we made the language model (though you can see where text-generation AI starts from!)\n",
    "\n",
    "Also note that the model is often crafting the response _in the form of a tweet!_\n",
    "\n",
    "We now save the model's encoder, which is the mathematical representation of what the language model \"understands\" about English patterns infused by our tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thkQAeQ2bVwr"
   },
   "outputs": [],
   "source": [
    "my_model.save_encoder('fine_tuned_enc')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zt6pDPEDbVww"
   },
   "source": [
    "## Building the classifier model\n",
    "\n",
    "This is the model that will use our langauge model **and** the hand-coded tweets to guess if new tweets are fear-mongering or not.\n",
    "\n",
    "We'll create a new data bunch that only grabs the hand-coded tweets and keeps track of the labels there (true or false, for fear-mingering). We also pass in the `vocab` -- which is the list of the most useful words from the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "ntIAhZbbbVw1",
    "outputId": "207cc9e9-9b36-4d7a-a20a-0dd613cd5222"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_csv(data_path, 'scored.csv', vocab=data_lm.vocab, text_cols='content', label_cols='either')\n",
    "\n",
    "data_clas.save('data_clas_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCwf-DyEbVxA"
   },
   "source": [
    "We can then create a model to classify tweets. You can see that in the next two lines we include the processed, hand-coded tweets (`data_clas`), the original Wikitext model (`AWD_LSTM`), and the knowledge we saved after infusing the language model with tweets (`fine_tuned_enc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlJKU0g3bVxA"
   },
   "outputs": [],
   "source": [
    "my_model = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "my_model.load_encoder('fine_tuned_enc');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Az5OuN6_hJaF"
   },
   "source": [
    "With neural networks, there are lots of tweaks you can adjust — known as \"hyperparameters\" — such as learning rate and momentum. The fast.ai defaults are pretty great, and the tools it has for finding the learning rate are super useful. I'm going to skip those details here for now. There's more to learn at [qz.ai](https://qz.ai) or at the [this great fast.ai course](https://course.fast.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "S5g2xmtlbVxJ",
    "outputId": "f3aefcce-8f20-4dc2-dab4-1af0c3c5e286"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.562637</td>\n",
       "      <td>0.328664</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.374253</td>\n",
       "      <td>0.228666</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.284790</td>\n",
       "      <td>0.229790</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.246976</td>\n",
       "      <td>0.216539</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.214918</td>\n",
       "      <td>0.239480</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.185822</td>\n",
       "      <td>0.230715</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model.fit_one_cycle(2, 1e-2, moms=(0.8,0.7))\n",
    "\n",
    "my_model.freeze_to(-2)\n",
    "my_model.fit_one_cycle(2, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
    "\n",
    "my_model.freeze_to(-3)\n",
    "my_model.fit_one_cycle(2, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-TSQ7iDTdIG"
   },
   "source": [
    "Let's give it an example ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mBAXEa2MbVxa",
    "outputId": "ba87b76a-48e0-4172-e6ff-6c1a500d3515"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category tensor(1), tensor(1), tensor([0.2109, 0.7891]))"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"Once again, at the direction of The Squad, @SpeakerPelosi is holding up funding while putting people’s livelihoods on the line so she can fund Green New Deal pet projects. Despicable.\"\n",
    "my_model.predict(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8u1ptJu1UmT9"
   },
   "source": [
    "`1` means true!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-GHPbx4KAvl"
   },
   "source": [
    "We can open the \"black box\" a little to see what words the model is keying into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "tzlfnHzgKAvm",
    "outputId": "9bef8e64-53d1-41b6-e613-573a38b4a053"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.322\" style=\"background-color: rgba(253, 184, 106, 0.5);\">xxbos</span> <span title=\"0.185\" style=\"background-color: rgba(239, 99, 62, 0.5);\">xxmaj</span> <span title=\"0.593\" style=\"background-color: rgba(219, 240, 143, 0.5);\">once</span> <span title=\"0.259\" style=\"background-color: rgba(249, 147, 84, 0.5);\">again</span> <span title=\"0.195\" style=\"background-color: rgba(241, 104, 64, 0.5);\">,</span> <span title=\"0.202\" style=\"background-color: rgba(244, 109, 67, 0.5);\">at</span> <span title=\"0.176\" style=\"background-color: rgba(237, 94, 60, 0.5);\">the</span> <span title=\"0.346\" style=\"background-color: rgba(253, 196, 115, 0.5);\">direction</span> <span title=\"0.126\" style=\"background-color: rgba(222, 63, 46, 0.5);\">of</span> <span title=\"0.122\" style=\"background-color: rgba(221, 61, 45, 0.5);\">xxmaj</span> <span title=\"0.200\" style=\"background-color: rgba(244, 109, 67, 0.5);\">the</span> <span title=\"0.143\" style=\"background-color: rgba(226, 73, 50, 0.5);\">xxmaj</span> <span title=\"0.706\" style=\"background-color: rgba(162, 215, 105, 0.5);\">squad</span> <span title=\"0.214\" style=\"background-color: rgba(245, 116, 70, 0.5);\">,</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">@speakerpelosi</span> <span title=\"0.181\" style=\"background-color: rgba(238, 97, 61, 0.5);\">is</span> <span title=\"0.243\" style=\"background-color: rgba(247, 137, 79, 0.5);\">holding</span> <span title=\"0.160\" style=\"background-color: rgba(231, 82, 54, 0.5);\">up</span> <span title=\"0.262\" style=\"background-color: rgba(249, 149, 85, 0.5);\">funding</span> <span title=\"0.264\" style=\"background-color: rgba(249, 149, 85, 0.5);\">while</span> <span title=\"0.455\" style=\"background-color: rgba(254, 241, 167, 0.5);\">putting</span> <span title=\"0.425\" style=\"background-color: rgba(254, 231, 151, 0.5);\">people</span> <span title=\"0.309\" style=\"background-color: rgba(253, 176, 99, 0.5);\">’s</span> <span title=\"0.620\" style=\"background-color: rgba(207, 234, 132, 0.5);\">livelihoods</span> <span title=\"0.202\" style=\"background-color: rgba(244, 109, 67, 0.5);\">on</span> <span title=\"0.124\" style=\"background-color: rgba(221, 61, 45, 0.5);\">the</span> <span title=\"0.205\" style=\"background-color: rgba(244, 111, 68, 0.5);\">line</span> <span title=\"0.205\" style=\"background-color: rgba(244, 111, 68, 0.5);\">so</span> <span title=\"0.183\" style=\"background-color: rgba(238, 97, 61, 0.5);\">she</span> <span title=\"0.143\" style=\"background-color: rgba(226, 73, 50, 0.5);\">can</span> <span title=\"0.277\" style=\"background-color: rgba(251, 159, 90, 0.5);\">fund</span> <span title=\"0.138\" style=\"background-color: rgba(225, 70, 49, 0.5);\">xxmaj</span> <span title=\"0.332\" style=\"background-color: rgba(253, 188, 109, 0.5);\">green</span> <span title=\"0.112\" style=\"background-color: rgba(217, 53, 41, 0.5);\">xxmaj</span> <span title=\"0.188\" style=\"background-color: rgba(240, 101, 63, 0.5);\">new</span> <span title=\"0.067\" style=\"background-color: rgba(198, 32, 38, 0.5);\">xxmaj</span> <span title=\"0.166\" style=\"background-color: rgba(233, 87, 57, 0.5);\">deal</span> <span title=\"0.081\" style=\"background-color: rgba(204, 37, 38, 0.5);\">xxunk</span> <span title=\"0.177\" style=\"background-color: rgba(237, 94, 60, 0.5);\">projects</span> <span title=\"0.076\" style=\"background-color: rgba(202, 35, 38, 0.5);\">.</span> <span title=\"0.073\" style=\"background-color: rgba(200, 33, 38, 0.5);\">xxmaj</span> <span title=\"0.254\" style=\"background-color: rgba(248, 142, 82, 0.5);\">xxunk</span> <span title=\"0.178\" style=\"background-color: rgba(237, 94, 60, 0.5);\">.</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = TextClassificationInterpretation.from_learner(my_model) \n",
    "interp.show_intrinsic_attention(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0qx4GnrwKAvp"
   },
   "source": [
    "Let's save our work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSOgwF1ybVyh"
   },
   "source": [
    "## Saving to Google Drive\n",
    "\n",
    "At present, your Google Colaboratory Notebook disappears when you close it — along with all of your data. If you'd like to save your model to your Google Drive, run the following cell and grant the permissions it requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "NtuaN76CKAvq",
    "outputId": "f79da09e-bb8e-4d74-a69d-57001bae5e00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/\"\n",
    "base_dir = root_dir + 'ai-workshop/candidate_tweets/'\n",
    "save_path = Path(base_dir)\n",
    "save_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uCWJOM1eKAvt"
   },
   "source": [
    "The next line will save everything we need for predictions to a file to your Google Drive in the `ai-workshops` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_s3cYJAKAvt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model.export(save_path/\"export-tweetmodel.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zW42zxWEKAvx"
   },
   "source": [
    "Later, to load the model into your code, connect to your Google drive using the same block above that starts `from google.colab import drive ...` and then run this:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2KTqNQyKAvy"
   },
   "outputs": [],
   "source": [
    "# load the model from the 'export.pkl' file on your Google Drive\n",
    "my_model = load_learner(save_path/\"export_tweetmodel.pkl\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57uA-44kVh_T"
   },
   "source": [
    "We used a model built this way to classify #txlege tweets as they were tweeted. For details about deploying a predictor in the cloud using Render, see our [blog post about building the checkable-tweets project](https://qz.ai/?p=89)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "newmark-candidate-tweets-ml.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
